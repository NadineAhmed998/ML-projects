{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35roXDEMudbw"
   },
   "source": [
    "# GUC Clustering Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCwbCzREudb1"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIiItKbYudb2"
   },
   "source": [
    "**Objective:** \n",
    "The objective of this project teach students how to apply clustering to real data sets\n",
    "\n",
    "The projects aims to teach student: \n",
    "* Which clustering approach to use\n",
    "* Compare between Kmeans, Hierarchal, DBScan, and Gaussian Mixtures  \n",
    "* How to tune the parameters of each data approach\n",
    "* What is the effect of different distance functions (optional) \n",
    "* How to evaluate clustering approachs \n",
    "* How to display the output\n",
    "* What is the effect of normalizing the data \n",
    "\n",
    "Students in this project will use ready-made functions from Sklearn, plotnine, numpy and pandas \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ps : This is dummy work and you won't find methods or a lot of loops , i have done them and saved them in a copy maybe for evaluation , but it caused my PC to be dead for a lot of time thats why i made it manually and not nested loops and methods.\n",
    "Again if you wanted them to be in nested loops of methods i have them done in a copy on my pc but i couldn'y submit it cause they take really a lot of time to run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MtHElDYdudb3"
   },
   "outputs": [],
   "source": [
    "# if plotnine is not installed in Jupter then use the following command to install it \n",
    "\n",
    "#!python -m pip install --upgrade pip\n",
    "#!pip install plotnine\n",
    "best=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RHS5ZoQudb4"
   },
   "source": [
    "Running this project require the following imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrueqJenudb5"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import datasets\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing as prep\n",
    "from sklearn.datasets import *\n",
    "#from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "   \n",
    "# StandardScaler is a function to normalize the data \n",
    "# You may also check MinMaxScaler and MaxAbsScaler \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ju2Zj6-nudb5"
   },
   "outputs": [],
   "source": [
    "# helper function that allows us to display data in 2 dimensions an highlights the clusters\n",
    "def display_cluster(X,km=[],num_clusters=0):\n",
    "    color = 'brgcmyk'  #List colors\n",
    "    alpha = 0.5  #color obaque\n",
    "    s = 20\n",
    "    if num_clusters == 0:\n",
    "        plt.scatter(X[:,0],X[:,1],c = color[0],alpha = alpha,s = s)\n",
    "    else:\n",
    "        for i in range(num_clusters):\n",
    "            plt.scatter(X[km.labels_==i,0],X[km.labels_==i,1],c = color[i],alpha = alpha,s=s)\n",
    "            plt.scatter(km.cluster_centers_[i][0],km.cluster_centers_[i][1],c = color[i], marker = 'x', s = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZnIbT3Mudb6"
   },
   "source": [
    "## Multi Blob Data Set \n",
    "* The Data Set generated below has 6 cluster with varying number of users and varing densities\n",
    "* Cluster the data set below using \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JeSqG318udb7",
    "outputId": "078fad92-3073-4558-b1e8-f0acd8d85d34"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "n_bins = 6  \n",
    "centers = [(-3, -3), (0, 0), (5,2.5),(-1, 4), (4, 6), (9,7)]\n",
    "Multi_blob_Data, y = make_blobs(n_samples=[100,150, 300, 400,300, 200], n_features=2, cluster_std=[1.3,0.6, 1.2, 1.7,0.9,1.7],\n",
    "                  centers=centers, shuffle=False, random_state=42)\n",
    "display_cluster(Multi_blob_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDSIGjubudb8"
   },
   "source": [
    "### Kmeans \n",
    "* Use Kmeans with different values of K to cluster the above data \n",
    "* Display the outcome of each value of K \n",
    "* Plot distortion function versus K and choose the approriate value of k \n",
    "* Plot the silhouette_score versus K and use it to choose the best K \n",
    "* Store the silhouette_score for the best K for later comparison with other clustering techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Ne3KmtPudb9"
   },
   "outputs": [],
   "source": [
    "    model = KMeans() \n",
    "    visualizer = KElbowVisualizer(model, k=(2,15), metric='distortion', timings=False)\n",
    "    visualizer.fit(Multi_blob_Data)    \n",
    "    visualizer.poof()\n",
    "    n=visualizer.elbow_value_.T\n",
    "    visualizer2 = KElbowVisualizer(model, k=(2,15), metric='silhouette', timings=False)\n",
    "    visualizer2.fit(Multi_blob_Data)\n",
    "    elbow_score=visualizer2.elbow_score_.T\n",
    "    km =KMeans(n_clusters =n).fit(Multi_blob_Data)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(Multi_blob_Data[:,0], Multi_blob_Data[:,1], c=km.labels_, cmap='viridis')\n",
    "    strm=\"the best sil score of Manhattan single is at cluster:\"\n",
    "    kk=\" and of value equal to:\"\n",
    "    best.append(strm+ \" \"+ str(elbow_score)+\" \"+kk+\" \"+str(n))\n",
    "    print(best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kE7dvpOAudb9"
   },
   "source": [
    "### Hierarchal Clustering\n",
    "* Use AgglomerativeClustering function to  to cluster the above data \n",
    "* In the  AgglomerativeClustering change the following parameters \n",
    "    * Affinity (use euclidean, manhattan and cosine)\n",
    "    * Linkage( use average and single )\n",
    "    * Distance_threshold (try different)\n",
    "* For each of these trials plot the Dendograph , calculate the silhouette_score and display the resulting clusters  \n",
    "* Find the set of paramters that would find result in the best silhouette_score and store this score for later comparison with other clustering techniques. \n",
    "* Record your observation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3O_6WwKoudb-"
   },
   "outputs": [],
   "source": [
    "clustering = AgglomerativeClustering().fit(Multi_blob_Data)\n",
    "clustering\n",
    "AgglomerativeClustering()\n",
    "clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are drawing the data to know by eyes how many clusters we can make\n",
    "labels = range(1, 11)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.subplots_adjust(bottom=0.1)\n",
    "plt.scatter(Multi_blob_Data[:,0],Multi_blob_Data[:,1], label='True Position')\n",
    "\n",
    "for label, x, y in zip(labels, Multi_blob_Data[:, 0], Multi_blob_Data[:, 1]):\n",
    "    plt.annotate(\n",
    "        label,\n",
    "        xy=(x, y), xytext=(-3, 3),\n",
    "        textcoords='offset points', ha='right', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bestselouette2=[]\n",
    "bestselouette3=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manhattan Hier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manhattan single Dendogram \n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Dendograms of single Manhattan distance\")\n",
    "dend = shc.dendrogram(shc.linkage(Multi_blob_Data, method='single',metric='cityblock'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "if mi==0.0:\n",
    "    mi=mi+0.1\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "print(mi,ma,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manhattan single before clustering\n",
    "rangee=[]\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster2 = AgglomerativeClustering(n_clusters=2, affinity='manhattan', linkage='single')\n",
    "cluster2.fit_predict(Multi_blob_Data)\n",
    "print(cluster2.labels_)\n",
    "plt.scatter(Multi_blob_Data[:,0],Multi_blob_Data[:,1], c=cluster2.labels_, cmap='viridis')\n",
    "rangee.append(np.array(cluster2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestselouette1=[]\n",
    "score=[]\n",
    "distanceofbestsill=[]\n",
    "strm=[]\n",
    "bestsil=[]\n",
    "strmm=[]\n",
    "kk=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "for i in np.arange(mi,ma,r):\n",
    "    cluster = AgglomerativeClustering(n_clusters=None, affinity='manhattan', linkage='single',distance_threshold=i)\n",
    "    cluster.fit_predict(Multi_blob_Data)\n",
    "    acluster.append(len(np.unique(cluster.labels_)))\n",
    "    score.append(silhouette_score(Multi_blob_Data, cluster.labels_, metric='manhattan'))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(Multi_blob_Data[:,0], Multi_blob_Data[:,1], c=cluster.labels_, cmap='viridis')\n",
    "    hi.append(i)\n",
    "bestsil.append(max(score))\n",
    "print(\"hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\")\n",
    "\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(\"jjjjjjjjjjjjjjjjijjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj\")\n",
    "print(acluster[iii])\n",
    "strm=\"the best sil score of Manhattan single is at cluster:\"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manhattan average Dendogram \n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of average Manhattan distance\")\n",
    "dend = shc.dendrogram(shc.linkage(Multi_blob_Data, method='average',metric='cityblock'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "if mi==0.0:\n",
    "    mi=mi+0.1\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "print(mi,ma,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manhattan single before clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster2 = AgglomerativeClustering(n_clusters=2, affinity='manhattan', linkage='average')\n",
    "cluster2.fit_predict(Multi_blob_Data)\n",
    "print(cluster2.labels_)\n",
    "plt.scatter(Multi_blob_Data[:,0],Multi_blob_Data[:,1], c=cluster2.labels_, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manhattan average after clustering \n",
    "bestselouette1=[]\n",
    "score=[]\n",
    "distanceofbestsill=[]\n",
    "strm=[]\n",
    "bestsil=[]\n",
    "strmm=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "for i in np.arange(mi,ma,r):\n",
    "    cluster = AgglomerativeClustering(n_clusters=None, affinity='manhattan', linkage='average',distance_threshold=i)\n",
    "    cluster.fit_predict(Multi_blob_Data)\n",
    "    score.append(silhouette_score(Multi_blob_Data, cluster.labels_, metric='manhattan'))\n",
    "    acluster.append(len(np.unique(cluster.labels_)))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(Multi_blob_Data[:,0], Multi_blob_Data[:,1], c=cluster.labels_, cmap='viridis')\n",
    "    hi.append(i)\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "strm=\"the best sil score of Manhattan average is at cluster:\"\n",
    "kk=\" and of value equal to:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eucleadian Hier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean single \n",
    "#before clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of single Euclidean distance\")\n",
    "dend = shc.dendrogram(shc.linkage(Multi_blob_Data, method='single'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "if mi==0.0:\n",
    "    mi=mi+0.1\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "print(mi,ma,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster11 = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='single')\n",
    "cluster11.fit_predict(Multi_blob_Data)\n",
    "print(cluster11.labels_)\n",
    "plt.scatter(Multi_blob_Data[:,0],Multi_blob_Data[:,1], c=cluster11.labels_, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "# Euclidean average after clustering\n",
    "indexat=[1.0,1.25,1.5,1.75,2.0,2.25,2.5,2.75]\n",
    "#for i in indexat:\n",
    "    #print(i)\n",
    "for i in np.arange(mi,ma,r):\n",
    "#for i in indexat :\n",
    "    \n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='euclidean', linkage='single',distance_threshold=i)\n",
    "    clusterEA.fit_predict(Multi_blob_Data)\n",
    "    score.append(silhouette_score(Multi_blob_Data, clusterEA.labels_, metric='euclidean'))\n",
    "    hi.append(i)\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(Multi_blob_Data[:,0], Multi_blob_Data[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "strm=\"the best sil score of Eucilidean single is at cluster of  \"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "\n",
    "kk=\" at distance threshold:\"\n",
    "#print(str(a[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean average before clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster1 = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='average')\n",
    "cluster1.fit_predict(Multi_blob_Data)\n",
    "print(cluster1.labels_)\n",
    "plt.scatter(Multi_blob_Data[:,0],Multi_blob_Data[:,1], c=cluster1.labels_, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of Average Euclidean distance\")\n",
    "dend = shc.dendrogram(shc.linkage(Multi_blob_Data, method='average'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "if mi==0.0:\n",
    "    mi=mi+0.1\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "print(mi,ma,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "# Euclidean average after clustering\n",
    "\n",
    "for i in np.arange(mi,ma,r):\n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='euclidean', linkage='average',distance_threshold=i)\n",
    "    clusterEA.fit_predict(Multi_blob_Data)\n",
    "    score.append(silhouette_score(Multi_blob_Data, clusterEA.labels_, metric='euclidean'))\n",
    "    hi.append(i)\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(Multi_blob_Data[:,0], Multi_blob_Data[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)+1\n",
    "print(iii)\n",
    "strm=\"the best sil score of Eucilidean average is at cluster of  \"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Hier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine average before clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of Cosine Average distance\")\n",
    "dend = shc.dendrogram(shc.linkage(Multi_blob_Data, method='average',metric='cosine'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "if mi==0.0:\n",
    "    mi=mi+0.1\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "print(mi,ma,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "clusterEA1 = AgglomerativeClustering(n_clusters=2, affinity='cosine', linkage='average')\n",
    "clusterEA1.fit_predict(Multi_blob_Data)\n",
    "print(clusterEA1.labels_)\n",
    "plt.scatter(Multi_blob_Data[:,0],Multi_blob_Data[:,1], c=clusterEA1.labels_, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "hi=[]\n",
    "# Euclidean average after clustering\n",
    "# heya men 0-1.6 bs msh zabta m3aya \n",
    "iteraty=[]\n",
    "acluster=[]\n",
    "for i in np.arange(mi,ma,r):\n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='cosine', linkage='average',distance_threshold=i)\n",
    "    clusterEA.fit_predict(Multi_blob_Data)\n",
    "    score.append(silhouette_score(Multi_blob_Data, clusterEA.labels_, metric='cosine'))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    hi.append(i)\n",
    "    plt.scatter(Multi_blob_Data[:,0], Multi_blob_Data[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "print(\"kkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk\")\n",
    "print(hi[iii])\n",
    "strm=\"the best sil score of cosine average is at cluster of  \"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cosine single before clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of single cosine distance\")\n",
    "dend = shc.dendrogram(shc.linkage(Multi_blob_Data, method='single',metric='cosine'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "clusterEA12 = AgglomerativeClustering(n_clusters=2, affinity='cosine', linkage='single')\n",
    "clusterEA12.fit_predict(Multi_blob_Data)\n",
    "print(clusterEA12.labels_)\n",
    "plt.scatter(Multi_blob_Data[:,0],Multi_blob_Data[:,1], c=clusterEA12.labels_, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cosine single after clustering\n",
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "# Euclidean average after clustering\n",
    "# heya men 0-1.6 bs msh zabta m3aya \n",
    "iteraty=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "for i in np.arange(mi,ma,r):\n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='cosine', linkage='single',distance_threshold=i)\n",
    "    clusterEA.fit_predict(Multi_blob_Data)\n",
    "    score.append(silhouette_score(Multi_blob_Data, clusterEA.labels_, metric='cosine'))\n",
    "    hi.append(i)\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(Multi_blob_Data[:,0], Multi_blob_Data[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "print(\"kkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk\")\n",
    "print(hi[iii])\n",
    "strm=\"the best sil score of cosine single is at cluster of  \"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster\n",
    "                                   [iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in bestselouette3:\n",
    "    print(each)\n",
    "    m=str(each[0])\n",
    "    n=str(each[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [] \n",
    "m = \"\"\n",
    "ar=[]\n",
    "final=[]\n",
    "[res.append(x) for x in bestselouette3 if x not in res]\n",
    "for each in res:\n",
    "    m=str(each[0])\n",
    "    n=str(each[1])\n",
    "    ar.append(n)\n",
    "    final.append(m)\n",
    "    final.append(n)\n",
    "    s=(max(ar))\n",
    "\n",
    "#print(final)   \n",
    "ss=final.index(s)\n",
    "sss=final[ss-1]\n",
    "zz=sss+\"  and is equal to \"+s\n",
    "print(zz)\n",
    "best.append(zz)\n",
    "print(best)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myJE7vQKudb-"
   },
   "source": [
    "### DBScan\n",
    "* Use DBScan function to  to cluster the above data \n",
    "* In the  DBscan change the following parameters \n",
    "    * EPS (from 0.1 to 3)\n",
    "    * Min_samples (from 5 to 25)\n",
    "* Plot the silhouette_score versus the variation in the EPS and the min_samples\n",
    "* Plot the resulting Clusters in this case \n",
    "* Find the set of paramters that would find result in the best silhouette_score and store this score for later comparison with other clustering techniques. \n",
    "* Record your observations and comments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QiQtpAt5udb_"
   },
   "outputs": [],
   "source": [
    "    xx=np.arange(0.1,3,0.1)\n",
    "    yy=range(5,25)\n",
    "    sil=np.empty((len(ii),len(jj)),float)\n",
    "    a=0\n",
    "    b=0\n",
    "    for i in xx :\n",
    "        for j in yy :\n",
    "            DBScan = DBSCAN(eps=i, min_samples=j).fit(Multi_blob_Data)\n",
    "            plt.scatter(Multi_blob_Data[:,0], Multi_blob_Data[:,1], c=DBScan.labels_, cmap='rainbow')\n",
    "            plt.title(\"eps=\"+str(i)[0:3]+\"   min_samples\"+str(j))\n",
    "            plt.show()\n",
    "            n=len(set(DBScan.labels_))\n",
    "            if(n>1):\n",
    "                sil[a][b]=silhouette_score(Multi_blob_Data,DBScan.labels_)         \n",
    "            else :\n",
    "                sil[a][b]=-1\n",
    "            b+=1\n",
    "        a+=1\n",
    "        b=0\n",
    "    plt.colorbar(plt.imshow(sil,cmap='viridis'))\n",
    "    plt.clf()\n",
    "    maxindex=np.unravel_index(sil.argmax(), sil.shape)\n",
    "    besteps=xx[maxindex[0]]\n",
    "    bestmin_samples=yy[maxindex[1]]\n",
    "    DBScan = DBSCAN(eps=besteps, min_samples=bestmin_samples).fit(Multi_blob_Data)\n",
    "    plt.scatter(Multi_blob_Data[:,0], Multi_blob_Data[:,1], c=DBScan.labels_, cmap='rainbow')\n",
    "    plt.title(\"eps=\"+str(best_eps)+\"   min_samples\"+str(bestmin_samples))\n",
    "    plt.show()\n",
    "    max_score=sil[maxindex[0]][maxindex[1]]\n",
    "    print(\"the best value of eps is: \" +str(best_eps))\n",
    "    print(\"the best value of min_samples is: \" +str(best_min_samples))\n",
    "    print(\"the max silhouette score is :  \" + str(max_score))\n",
    "   \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ip16g1QFudb_"
   },
   "source": [
    "### Gaussian Mixture\n",
    "* Use GaussianMixture function to cluster the above data \n",
    "* In GMM change the covariance_type and check the difference in the resulting proabability fit \n",
    "* Use a 2D contour plot to plot the resulting distribution (the components of the GMM) as well as the total Gaussian mixture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "n_bins = 6  \n",
    "centers = [(-3, -3), (0, 0), (5,2.5),(-1, 4), (4, 6), (9,7)]\n",
    "Multi_blob_Data, y = make_blobs(n_samples=[100,150, 300, 400,300, 200], n_features=2, cluster_std=[1.3,0.6, 1.2, 1.7,0.9,1.7],\n",
    "                  centers=centers, shuffle=False, random_state=42)\n",
    "display_cluster(Multi_blob_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import mixture\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,10):\n",
    "    gmm = GaussianMixture(n_components=i,covariance_type='full')\n",
    "    gmm.fit(Multi_blob_Data)\n",
    "    labels = gmm.predict(Multi_blob_Data)\n",
    "    plt.scatter(Multi_blob_Data[:, 0], Multi_blob_Data[:, 1], c=labels, cmap='viridis');\n",
    "    X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "    XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "    Z = gmm.score_samples(XX)\n",
    "    Z = Z.reshape((50,50))\n",
    "    plt.contour(X, Y, Z,levels=50) \n",
    "    plt.scatter(Multi_blob_Data[:, 0], Multi_blob_Data[:, 1], c=labels, cmap='viridis');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,10):\n",
    "    gmm = GaussianMixture(n_components=i,covariance_type='tied')\n",
    "    gmm.fit(Multi_blob_Data)\n",
    "    labels = gmm.predict(Multi_blob_Data)\n",
    "    plt.scatter(Multi_blob_Data[:, 0], Multi_blob_Data[:, 1], c=labels, cmap='viridis');\n",
    "    X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "    XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "    Z = gmm.score_samples(XX)\n",
    "    Z = Z.reshape((50,50))\n",
    "    plt.contour(X, Y, Z,levels=50) \n",
    "    plt.scatter(Multi_blob_Data[:, 0], Multi_blob_Data[:, 1], c=labels, cmap='viridis');\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gmm = GaussianMixture(n_components=6)\n",
    "#gmm.fit(Multi_blob_Data)\n",
    "#labels = gmm.predict(Multi_blob_Data)\n",
    "#plt.scatter(Multi_blob_Data[:, 0], Multi_blob_Data[:, 1], c=labels, cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "#XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "#Z = gmm.score_samples(XX)\n",
    "#Z = Z.reshape((50,50))\n",
    "#plt.contour(X, Y, Z,levels=50) \n",
    "#plt.scatter(Multi_blob_Data[:, 0], Multi_blob_Data[:, 1], c=labels, cmap='viridis');\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,10):\n",
    "    gmm = GaussianMixture(n_components=i,covariance_type='diag')\n",
    "    gmm.fit(Multi_blob_Data)\n",
    "    labels = gmm.predict(Multi_blob_Data)\n",
    "    plt.scatter(Multi_blob_Data[:, 0], Multi_blob_Data[:, 1], c=labels, cmap='viridis');\n",
    "    X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "    XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "    Z = gmm.score_samples(XX)\n",
    "    Z = Z.reshape((50,50))\n",
    "    plt.contour(X, Y, Z,levels=50) \n",
    "    plt.scatter(Multi_blob_Data[:, 0], Multi_blob_Data[:, 1], c=labels, cmap='viridis');\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,10):\n",
    "    gmm = GaussianMixture(n_components=i,covariance_type='spherical')\n",
    "    gmm.fit(Multi_blob_Data)\n",
    "    labels = gmm.predict(Multi_blob_Data)\n",
    "    plt.scatter(Multi_blob_Data[:, 0], Multi_blob_Data[:, 1], c=labels, cmap='viridis');\n",
    "    X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "    XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "    Z = gmm.score_samples(XX)\n",
    "    Z = Z.reshape((50,50))\n",
    "    plt.contour(X, Y, Z,levels=50) \n",
    "    plt.scatter(Multi_blob_Data[:, 0], Multi_blob_Data[:, 1], c=labels, cmap='viridis');\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m92lZkkyudb_"
   },
   "source": [
    "## iris data set \n",
    "The iris data set is test data set that is part of the Sklearn module \n",
    "which contains 150 records each with 4 features. All the features are represented by real numbers \n",
    "\n",
    "The data represents three classes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_QaCWyyCudcA",
    "outputId": "79c14dba-80cf-4d96-e69d-70763b789faf"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_data = load_iris()\n",
    "iris_data.target[[10, 25, 50]]\n",
    "#array([0, 0, 1])\n",
    "mmm=list(iris_data.target_names)\n",
    "print(mmm)\n",
    "['setosa', 'versicolor', 'virginica']\n",
    "irisdata=np.array(iris_data.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.DataFrame(iris_data.data, columns = iris_data.feature_names)\n",
    "iris['target'] = iris_data.target\n",
    "X = iris_data.data\n",
    "sepal=np.array(iris[iris.columns[0:2]])\n",
    "print(sepal)\n",
    "petal=np.array(iris[iris.columns[2:4]])\n",
    "print(petal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = AgglomerativeClustering().fit(Multi_blob_Data)\n",
    "clustering\n",
    "AgglomerativeClustering()\n",
    "clustering.labels_\n",
    "#here we are drawing the data to know by eyes how many clusters we can make\n",
    "labels = range(1, 11)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.subplots_adjust(bottom=0.1)\n",
    "plt.scatter(irisdata[:,0],irisdata[:,1], label='True Position')\n",
    "\n",
    "for label, x, y in zip(labels, irisdata[:, 0], irisdata[:, 1]):\n",
    "    plt.annotate(\n",
    "        label,\n",
    "        xy=(x, y), xytext=(-3, 3),\n",
    "        textcoords='offset points', ha='right', va='bottom')\n",
    "plt.show()\n",
    "bestselouette2=[]\n",
    "bestselouette3=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisdata=sepal\n",
    "irisdata2=petal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = KMeans() \n",
    "    visualizer = KElbowVisualizer(model, k=(2,15), metric='distortion', timings=False)\n",
    "    visualizer.fit(irisdata)    \n",
    "    visualizer.poof()\n",
    "    n=visualizer.elbow_value_.T\n",
    "    visualizer2 = KElbowVisualizer(model, k=(2,15), metric='silhouette', timings=False)\n",
    "    visualizer2.fit(irisdata)\n",
    "    elbow_score=visualizer2.elbow_score_.T\n",
    "    km =KMeans(n_clusters =n).fit(irisdata)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(irisdata[:,0], irisdata[:,1], c=km.labels_, cmap='viridis')\n",
    "    strm=\"the best sil score of Manhattan single is at cluster:\"\n",
    "    kk=\" and of value equal to:\"\n",
    "    print(strm+ \" \"+ str(elbow_score)+\" \"+kk+\" \"+str(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = KMeans() \n",
    "    visualizer = KElbowVisualizer(model, k=(2,15), metric='distortion', timings=False)\n",
    "    visualizer.fit(irisdata2)    \n",
    "    visualizer.poof()\n",
    "    n=visualizer.elbow_value_.T\n",
    "    visualizer2 = KElbowVisualizer(model, k=(2,15), metric='silhouette', timings=False)\n",
    "    visualizer2.fit(irisdata2)\n",
    "    elbow_score=visualizer2.elbow_score_.T\n",
    "    km =KMeans(n_clusters =n).fit(irisdata2)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(irisdata2[:,0], irisdata2[:,1], c=km.labels_, cmap='viridis')\n",
    "    strm=\"the best sil score of Manhattan single is at cluster:\"\n",
    "    kk=\" and of value equal to:\"\n",
    "    print(strm+ \" \"+ str(elbow_score)+\" \"+kk+\" \"+str(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manhattan single Dendogram \n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of single Manhattan distance\")\n",
    "dend = shc.dendrogram(shc.linkage(irisdata, method='single',metric='cityblock'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "\n",
    "#Manhattan single before clustering\n",
    "rangee=[]\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster2 = AgglomerativeClustering(n_clusters=2, affinity='manhattan', linkage='single')\n",
    "cluster2.fit_predict(irisdata)\n",
    "print(cluster2.labels_)\n",
    "plt.scatter(irisdata[:,0],irisdata[:,1], c=cluster2.labels_, cmap='viridis')\n",
    "rangee.append(np.array(cluster2))#Manhattan single after clustering \n",
    "bestselouette1=[]\n",
    "score=[]\n",
    "distanceofbestsill=[]\n",
    "strm=[]\n",
    "bestsil=[]\n",
    "strmm=[]\n",
    "kk=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "for i in np.arange(mi,ma,r):\n",
    "    cluster = AgglomerativeClustering(n_clusters=None, affinity='manhattan', linkage='single',distance_threshold=i)\n",
    "    cluster.fit_predict(irisdata)\n",
    "    acluster.append(len(np.unique(cluster.labels_)))\n",
    "    score.append(silhouette_score(irisdata, cluster.labels_, metric='manhattan'))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(irisdata[:,0], irisdata[:,1], c=cluster.labels_, cmap='viridis')\n",
    "    hi.append(i)\n",
    "bestsil.append(max(score))\n",
    "print(\"hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\")\n",
    "#print(a)\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(\"jjjjjjjjjjjjjjjjijjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj\")\n",
    "#print(a[iii])\n",
    "strm=\"the best sil score of Manhattan single is at cluster:\"\n",
    "kk=\" at distance threshold:\"\n",
    "#print(str(a[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manhattan single Dendogram \n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of single Manhattan distance\")\n",
    "dend = shc.dendrogram(shc.linkage(irisdata, method='single',metric='cityblock'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "\n",
    "#Manhattan single before clustering\n",
    "rangee=[]\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster2 = AgglomerativeClustering(n_clusters=2, affinity='manhattan', linkage='single')\n",
    "cluster2.fit_predict(irisdata2)\n",
    "print(cluster2.labels_)\n",
    "plt.scatter(irisdata2[:,0],irisdata2[:,1], c=cluster2.labels_, cmap='viridis')\n",
    "rangee.append(np.array(cluster2))#Manhattan single after clustering \n",
    "bestselouette1=[]\n",
    "score=[]\n",
    "distanceofbestsill=[]\n",
    "strm=[]\n",
    "bestsil=[]\n",
    "strmm=[]\n",
    "kk=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "for i in np.arange(0.1,1,0.25):\n",
    "    cluster = AgglomerativeClustering(n_clusters=None, affinity='manhattan', linkage='single',distance_threshold=i)\n",
    "    cluster.fit_predict(irisdata2)\n",
    "    acluster.append(len(np.unique(cluster.labels_)))\n",
    "    score.append(silhouette_score(irisdata2, cluster.labels_, metric='manhattan'))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(irisdata2[:,0], irisdata2[:,1], c=cluster.labels_, cmap='viridis')\n",
    "    hi.append(i)\n",
    "bestsil.append(max(score))\n",
    "print(\"hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\")\n",
    "#print(a)\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(\"jjjjjjjjjjjjjjjjijjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj\")\n",
    "#print(a[iii])\n",
    "strm=\"the best sil score of Manhattan single is at cluster:\"\n",
    "kk=\" at distance threshold:\"\n",
    "#print(str(a[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manhattan average Dendogram \n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of average Manhattan distance\")\n",
    "dend = shc.dendrogram(shc.linkage(irisdata, method='average',metric='cityblock'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "#Manhattan single before clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster2 = AgglomerativeClustering(n_clusters=2, affinity='manhattan', linkage='average')\n",
    "cluster2.fit_predict(irisdata)\n",
    "print(cluster2.labels_)\n",
    "plt.scatter(irisdata[:,0],irisdata[:,1], c=cluster2.labels_, cmap='viridis')\n",
    "#Manhattan average after clustering \n",
    "bestselouette1=[]\n",
    "score=[]\n",
    "distanceofbestsill=[]\n",
    "strm=[]\n",
    "bestsil=[]\n",
    "strmm=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "for i in np.arange(mi,ma,r):\n",
    "    cluster = AgglomerativeClustering(n_clusters=None, affinity='manhattan', linkage='average',distance_threshold=i)\n",
    "    cluster.fit_predict(irisdata)\n",
    "    score.append(silhouette_score(irisdata, cluster.labels_, metric='manhattan'))\n",
    "    acluster.append(len(np.unique(cluster.labels_)))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(irisdata[:,0], irisdata[:,1], c=cluster.labels_, cmap='viridis')\n",
    "    hi.append(i)\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "strm=\"the best sil score of Manhattan average is at cluster:\"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10, 7))\n",
    "#plt.title(\"Customer Dendograms of single Euclidean distance\")\n",
    "#dend = shc.dendrogram(shc.linkage(irisdata, method='single'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean single \n",
    "#before clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of single Euclidean distance\")\n",
    "dend = shc.dendrogram(shc.linkage(Multi_blob_Data, method='single'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster11 = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='single')\n",
    "cluster11.fit_predict(irisdata)\n",
    "print(cluster11.labels_)\n",
    "plt.scatter(irisdata[:,0],irisdata[:,1], c=cluster11.labels_, cmap='viridis')\n",
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "# Euclidean average after clustering\n",
    "indexat=[1.0,1.25,1.5,1.75,2.0,2.25,2.5,2.75]\n",
    "#for i in indexat:\n",
    "    #print(i)\n",
    "for i in np.arange(0.25,1.75,0.25):\n",
    "#for i in indexat :\n",
    "    \n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='euclidean', linkage='single',distance_threshold=i)\n",
    "    clusterEA.fit_predict(irisdata)\n",
    "    score.append(silhouette_score(irisdata, clusterEA.labels_, metric='euclidean'))\n",
    "    hi.append(i)\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(irisdata[:,0], irisdata[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "strm=\"the best sil score of Eucilidean single is at cluster of  \"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "\n",
    "kk=\" at distance threshold:\"\n",
    "#print(str(a[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean single \n",
    "#before clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of single Euclidean distance\")\n",
    "dend = shc.dendrogram(shc.linkage(Multi_blob_Data, method='single'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster11 = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='single')\n",
    "cluster11.fit_predict(irisdata2)\n",
    "print(cluster11.labels_)\n",
    "plt.scatter(irisdata2[:,0],irisdata2[:,1], c=cluster11.labels_, cmap='viridis')\n",
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "# Euclidean average after clustering\n",
    "indexat=[1.0,1.25,1.5,1.75,2.0,2.25,2.5,2.75]\n",
    "#for i in indexat:\n",
    "    #print(i)\n",
    "for i in np.arange(0.25,1.75,0.25):\n",
    "#for i in indexat :\n",
    "    \n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='euclidean', linkage='single',distance_threshold=i)\n",
    "    clusterEA.fit_predict(irisdata2)\n",
    "    score.append(silhouette_score(irisdata2, clusterEA.labels_, metric='euclidean'))\n",
    "    hi.append(i)\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(irisdata2[:,0], irisdata2[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "strm=\"the best sil score of Eucilidean single is at cluster of  \"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "\n",
    "kk=\" at distance threshold:\"\n",
    "#print(str(a[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean average before clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of single Euclidean distance\")\n",
    "dend = shc.dendrogram(shc.linkage(irisdata, method='single'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster1 = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='average')\n",
    "cluster1.fit_predict(irisdata)\n",
    "print(cluster1.labels_)\n",
    "plt.scatter(irisdata[:,0],irisdata[:,1], c=cluster1.labels_, cmap='viridis')\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of Average Euclidean distance\")\n",
    "dend = shc.dendrogram(shc.linkage(irisdata, method='average'))\n",
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "# Euclidean average after clustering\n",
    "\n",
    "for i in np.arange(mi,ma,r):\n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='euclidean', linkage='average',distance_threshold=i)\n",
    "    clusterEA.fit_predict(irisdata)\n",
    "    score.append(silhouette_score(irisdata, clusterEA.labels_, metric='euclidean'))\n",
    "    hi.append(i)\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(irisdata[:,0], irisdata[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "strm=\"the best sil score of Eucilidean average is at cluster of  \"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean average before clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of single Euclidean distance\")\n",
    "dend = shc.dendrogram(shc.linkage(irisdata, method='single'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster1 = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='average')\n",
    "cluster1.fit_predict(irisdata2)\n",
    "print(cluster1.labels_)\n",
    "plt.scatter(irisdata2[:,0],irisdata2[:,1], c=cluster1.labels_, cmap='viridis')\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of Average Euclidean distance\")\n",
    "dend = shc.dendrogram(shc.linkage(irisdata2, method='average'))\n",
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "# Euclidean average after clustering\n",
    "\n",
    "for i in np.arange(mi,ma,r):\n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='euclidean', linkage='average',distance_threshold=i)\n",
    "    clusterEA.fit_predict(irisdata2)\n",
    "    score.append(silhouette_score(irisdata2, clusterEA.labels_, metric='euclidean'))\n",
    "    hi.append(i)\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(irisdata2[:,0], irisdata2[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "strm=\"the best sil score of Eucilidean average is at cluster of  \"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cosine average before clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of Cosine Average distance\")\n",
    "dend = shc.dendrogram(shc.linkage(irisdata, method='average',metric='cosine'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "clusterEA1 = AgglomerativeClustering(n_clusters=2, affinity='cosine', linkage='average')\n",
    "clusterEA1.fit_predict(irisdata)\n",
    "print(clusterEA1.labels_)\n",
    "plt.scatter(irisdata[:,0],irisdata[:,1], c=clusterEA1.labels_, cmap='viridis')\n",
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "hi=[]\n",
    "# Euclidean average after clustering\n",
    "# heya men 0-1.6 bs msh zabta m3aya \n",
    "iteraty=[]\n",
    "acluster=[]\n",
    "for i in np.arange(mi,ma,r):\n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='cosine', linkage='average',distance_threshold=i)\n",
    "    clusterEA.fit_predict(irisdata)\n",
    "    score.append(silhouette_score(irisdata, clusterEA.labels_, metric='cosine'))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    hi.append(i)\n",
    "    plt.scatter(irisdata[:,0], irisdata[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "print(\"kkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk\")\n",
    "print(hi[iii])\n",
    "strm=\"the best sil score of cosine average is at cluster of  \"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cosine average before clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of Cosine Average distance\")\n",
    "dend = shc.dendrogram(shc.linkage(irisdata2, method='average',metric='cosine'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "clusterEA1 = AgglomerativeClustering(n_clusters=2, affinity='cosine', linkage='average')\n",
    "clusterEA1.fit_predict(irisdata2)\n",
    "print(clusterEA1.labels_)\n",
    "plt.scatter(irisdata2[:,0],irisdata2[:,1], c=clusterEA1.labels_, cmap='viridis')\n",
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "hi=[]\n",
    "# Euclidean average after clustering\n",
    "# heya men 0-1.6 bs msh zabta m3aya \n",
    "iteraty=[]\n",
    "acluster=[]\n",
    "for i in np.arange(mi,ma,r):\n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='cosine', linkage='average',distance_threshold=i)\n",
    "    clusterEA.fit_predict(irisdata2)\n",
    "    score.append(silhouette_score(irisdata2, clusterEA.labels_, metric='cosine'))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    hi.append(i)\n",
    "    plt.scatter(irisdata2[:,0], irisdata2[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "print(\"kkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk\")\n",
    "print(hi[iii])\n",
    "strm=\"the best sil score of cosine average is at cluster of  \"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine single before clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of single cosine distance\")\n",
    "dend = shc.dendrogram(shc.linkage(irisdata, method='single',metric='cosine'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "clusterEA12 = AgglomerativeClustering(n_clusters=2, affinity='cosine', linkage='single')\n",
    "clusterEA12.fit_predict(irisdata)\n",
    "print(clusterEA12.labels_)\n",
    "plt.scatter(irisdata[:,0],irisdata[:,1], c=clusterEA12.labels_, cmap='viridis')\n",
    "# cosine single after clustering\n",
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "# Euclidean average after clustering\n",
    "# heya men 0-1.6 bs msh zabta m3aya \n",
    "iteraty=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "for i in np.arange(mi,ma,r):\n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='cosine', linkage='single',distance_threshold=i)\n",
    "    clusterEA.fit_predict(irisdata)\n",
    "    score.append(silhouette_score(irisdata, clusterEA.labels_, metric='cosine'))\n",
    "    hi.append(i)\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(irisdata[:,0], irisdata[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "print(\"kkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk\")\n",
    "print(hi[iii])\n",
    "strm=\"the best sil score of cosine single is at cluster of  \"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster\n",
    "                                   [iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine single before clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of single cosine distance\")\n",
    "dend = shc.dendrogram(shc.linkage(irisdata2, method='single',metric='cosine'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "clusterEA12 = AgglomerativeClustering(n_clusters=2, affinity='cosine', linkage='single')\n",
    "clusterEA12.fit_predict(irisdata2)\n",
    "print(clusterEA12.labels_)\n",
    "plt.scatter(irisdata2[:,0],irisdata2[:,1], c=clusterEA12.labels_, cmap='viridis')\n",
    "# cosine single after clustering\n",
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "# Euclidean average after clustering\n",
    "# heya men 0-1.6 bs msh zabta m3aya \n",
    "iteraty=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "for i in np.arange(mi,ma,r):\n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='cosine', linkage='single',distance_threshold=i)\n",
    "    clusterEA.fit_predict(irisdata2)\n",
    "    score.append(silhouette_score(irisdata2, clusterEA.labels_, metric='cosine'))\n",
    "    hi.append(i)\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(irisdata2[:,0], irisdata2[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "print(\"kkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk\")\n",
    "print(hi[iii])\n",
    "strm=\"the best sil score of cosine single is at cluster of  \"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster\n",
    "                                   [iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in bestselouette3:\n",
    "    print(each)\n",
    "    m=str(each[0])\n",
    "    n=str(each[1])\n",
    "res = [] \n",
    "m = \"\"\n",
    "ar=[]\n",
    "final=[]\n",
    "[res.append(x) for x in bestselouette3 if x not in res]\n",
    "for each in res:\n",
    "    m=str(each[0])\n",
    "    n=str(each[1])\n",
    "    ar.append(n)\n",
    "    final.append(m)\n",
    "    final.append(n)\n",
    "    s=(max(ar))\n",
    "\n",
    "#print(final)   \n",
    "ss=final.index(s)\n",
    "sss=final[ss-1]\n",
    "print (\"The best technique and the best score are                                       :                                 \")\n",
    "print(sss+\"  and is equal to \"+s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisdata=sepal\n",
    "irisdata1=petal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    xx=np.arange(0.1,3,0.1)\n",
    "    yy=range(5,25)\n",
    "    sil=np.empty((len(ii),len(jj)),float)\n",
    "    a=0\n",
    "    b=0\n",
    "    for i in xx :\n",
    "        for j in yy :\n",
    "            DBScan = DBSCAN(eps=i, min_samples=j).fit(irisdata)\n",
    "            plt.scatter(irisdata[:,0], irisdata[:,1], c=DBScan.labels_, cmap='rainbow')\n",
    "            plt.title(\"eps=\"+str(i)[0:3]+\"   min_samples\"+str(j))\n",
    "            plt.show()\n",
    "            n=len(set(DBScan.labels_))\n",
    "            if(n>1):\n",
    "                sil[a][b]=silhouette_score(irisdata,DBScan.labels_)         \n",
    "            else :\n",
    "                sil[a][b]=-1\n",
    "            b+=1\n",
    "        a+=1\n",
    "        b=0\n",
    "    plt.colorbar(plt.imshow(sil,cmap='viridis'))\n",
    "    plt.clf()\n",
    "    maxindex=np.unravel_index(sil.argmax(), sil.shape)\n",
    "    besteps=xx[maxindex[0]]\n",
    "    bestmin_samples=yy[maxindex[1]]\n",
    "    DBScan = DBSCAN(eps=besteps, min_samples=bestmin_samples).fit(irisdata)\n",
    "    plt.scatter(irisdata[:,0], irisdata[:,1], c=DBScan.labels_, cmap='rainbow')\n",
    "    plt.title(\"eps=\"+str(best_eps)+\"   min_samples\"+str(bestmin_samples))\n",
    "    plt.show()\n",
    "    max_score=sil[maxindex[0]][maxindex[1]]\n",
    "    print(\"the best value of eps is: \" +str(best_eps))\n",
    "    print(\"the best value of min_samples is: \" +str(best_min_samples))\n",
    "    print(\"the max silhouette score is :  \" + str(max_score))  \n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    xx=np.arange(0.1,3,0.1)\n",
    "    yy=range(5,25)\n",
    "    sil=np.empty((len(ii),len(jj)),float)\n",
    "    a=0\n",
    "    b=0\n",
    "    for i in xx :\n",
    "        for j in yy :\n",
    "            DBScan = DBSCAN(eps=i, min_samples=j).fit(irisdata1)\n",
    "            plt.scatter(irisdata1[:,0], irisdata1[:,1], c=DBScan.labels_, cmap='rainbow')\n",
    "            plt.title(\"eps=\"+str(i)[0:3]+\"   min_samples\"+str(j))\n",
    "            plt.show()\n",
    "            n=len(set(DBScan.labels_))\n",
    "            if(n>1):\n",
    "                sil[a][b]=silhouette_score(irisdata1,DBScan.labels_)         \n",
    "            else :\n",
    "                sil[a][b]=-1\n",
    "            b+=1\n",
    "        a+=1\n",
    "        b=0\n",
    "    plt.colorbar(plt.imshow(sil,cmap='viridis'))\n",
    "    plt.clf()\n",
    "    maxindex=np.unravel_index(sil.argmax(), sil.shape)\n",
    "    besteps=xx[maxindex[0]]\n",
    "    bestmin_samples=yy[maxindex[1]]\n",
    "    DBScan = DBSCAN(eps=besteps, min_samples=bestmin_samples).fit(irisdata1)\n",
    "    plt.scatter(irisdata1[:,0], irisdata1[:,1], c=DBScan.labels_, cmap='rainbow')\n",
    "    plt.title(\"eps=\"+str(best_eps)+\"   min_samples\"+str(bestmin_samples))\n",
    "    plt.show()\n",
    "    max_score=sil[maxindex[0]][maxindex[1]]\n",
    "    print(\"the best value of eps is: \" +str(best_eps))\n",
    "    print(\"the best value of min_samples is: \" +str(best_min_samples))\n",
    "    print(\"the max silhouette score is :  \" + str(max_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,10):\n",
    "            GM = GaussianMixture(n_components=i,covariance_type='full').fit(sepal)\n",
    "            plt.scatter(sepal[:, 0], sepal[:, 1], c=GM.predict(sepal), cmap='rainbow');\n",
    "            X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "            XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "            Z = GM.score_samples(XX)\n",
    "            Z = Z.reshape((50,50))\n",
    "            plt.contour(X, Y, Z,levels=50) \n",
    "            plt.title('Guassian full sepal')\n",
    "            plt.scatter(sepal[:, 0], sepal[:, 1], c=GM.predict(sepal), cmap='rainbow');\n",
    "            plt.show()\n",
    "for i in range(2,10):          \n",
    "            GM = GaussianMixture(n_components=i,covariance_type='spherical').fit(sepal)\n",
    "            plt.scatter(sepal[:, 0], sepal[:, 1], c=GM.predict(sepal), cmap='rainbow');\n",
    "            X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "            XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "            Z = GM.score_samples(XX)\n",
    "            Z = Z.reshape((50,50))\n",
    "            plt.contour(X, Y, Z,levels=50)\n",
    "            plt.title('Guassian spherical sepal')\n",
    "            plt.scatter(sepal[:, 0], sepal[:, 1], c=GM.predict(sepal), cmap='rainbow');\n",
    "            plt.show()\n",
    "for i in range(2,10):\n",
    "            GM = GaussianMixture(n_components=i,covariance_type='tied').fit(sepal)\n",
    "            plt.scatter(sepal[:, 0], sepal[:, 1], c=GM.predict(sepal), cmap='rainbow');\n",
    "            X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "            XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "            Z = GM.score_samples(XX)\n",
    "            Z = Z.reshape((50,50))\n",
    "            plt.contour(X, Y, Z,levels=50)\n",
    "            plt.title('Guassian tied sepal')\n",
    "            plt.scatter(sepal[:, 0], sepal[:, 1], c=GM.predict(sepal), cmap='rainbow');\n",
    "            plt.show()\n",
    "for i in range(2,10):\n",
    "            GM = GaussianMixture(n_components=i,covariance_type='diag').fit(sepal)\n",
    "            plt.scatter(sepal[:, 0], sepal[:, 1], c=GM.predict(sepal), cmap='rainbow');\n",
    "            X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "            XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "            Z = GM.score_samples(XX)\n",
    "            Z = Z.reshape((50,50))\n",
    "            plt.contour(X, Y, Z,levels=50) \n",
    "            plt.title('Guassian diag sepal')\n",
    "            plt.scatter(sepal[:, 0], sepal[:, 1], c=GM.predict(sepal), cmap='rainbow');\n",
    "            plt.show()\n",
    "            \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for i in range(2,10):            \n",
    "            GM = GaussianMixture(n_components=i,covariance_type='full').fit(petal)\n",
    "            plt.scatter(petal[:, 0], petal[:, 1], c=GM.predict(petal), cmap='rainbow');\n",
    "            X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "            XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "            Z = GM.score_samples(XX)\n",
    "            Z = Z.reshape((50,50))\n",
    "            plt.contour(X, Y, Z,levels=50) \n",
    "            plt.title('Guassian full petal')\n",
    "            plt.scatter(petal[:, 0], petal[:, 1], c=GM.predict(petal), cmap='rainbow');\n",
    "            plt.show()\n",
    "    for i in range(2,10):\n",
    "            GM = GaussianMixture(n_components=i,covariance_type='spherical').fit(petal)\n",
    "            plt.scatter(petal[:, 0], petal[:, 1], c=GM.predict(petal), cmap='rainbow');\n",
    "            X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "            XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "            Z = GM.score_samples(XX)\n",
    "            Z = Z.reshape((50,50))\n",
    "            plt.contour(X, Y, Z,levels=50) \n",
    "            plt.title('Guassian spherical petal')\n",
    "            plt.scatter(petal[:, 0], petal[:, 1], c=GM.predict(petal), cmap='rainbow');\n",
    "            plt.show()\n",
    "    for i in range(2,10):\n",
    "            GM = GaussianMixture(n_components=i,covariance_type='tied').fit(petal)\n",
    "            plt.scatter(petal[:, 0], petal[:, 1], c=GM.predict(petal), cmap='rainbow');\n",
    "            X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "            XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "            Z = GM.score_samples(XX)\n",
    "            Z = Z.reshape((50,50))\n",
    "            plt.contour(X, Y, Z,levels=50) \n",
    "            plt.title('Guassian tied petal')\n",
    "            plt.scatter(petal[:, 0], petal[:, 1], c=GM.predict(petal), cmap='rainbow');\n",
    "            plt.show()\n",
    "    for i in range(2,10):\n",
    "            GM = GaussianMixture(n_components=i,covariance_type='diag').fit(petal)\n",
    "            plt.scatter(petal[:, 0], petal[:, 1], c=GM.predict(petal), cmap='rainbow');\n",
    "            X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "            XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "            Z = GM.score_samples(XX)\n",
    "            Z = Z.reshape((50,50))\n",
    "            plt.contour(X, Y, Z,levels=50) \n",
    "            plt.title('Guassian diag petal')\n",
    "            plt.scatter(petal[:, 0], petal[:, 1], c=GM.predict(petal), cmap='rainbow');\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WyoCVfyMudcA"
   },
   "source": [
    "* Repeat all the above clustering approaches and steps on the above data \n",
    "* Normalize the data then repeat all the above steps \n",
    "* Compare between the different clustering approaches "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2oBmWT2udcA"
   },
   "source": [
    "## Customer dataset\n",
    "Repeat all the above on the customer data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data =pd.read_csv('Customer data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.head()\n",
    "my_data=my_data.drop(\"ID\",axis=1)\n",
    "my_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(my_data.drop('Settlement size',axis=1))\n",
    "scaled_features = scaler.transform(my_data.drop('Settlement size',axis=1))\n",
    "customer_scaled = pd.DataFrame(scaled_features,columns=my_data.columns[:-1])\n",
    "customer_scaled.head()\n",
    "sepal_scaled=np.array(customer_scaled[customer_scaled.columns[0:2]])\n",
    "petal_scaled=np.array(customer_scaled[customer_scaled.columns[2:4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbb=np.array(my_data)\n",
    "clustering = AgglomerativeClustering().fit(petal_scaled)\n",
    "clustering\n",
    "AgglomerativeClustering()\n",
    "clustering.labels_\n",
    "#here we are drawing the data to know by eyes how many clusters we can make\n",
    "labels = range(1, 11)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.subplots_adjust(bottom=0.1)\n",
    "plt.scatter(petal_scaled[:,0],petal_scaled[:,1], label='True Position')\n",
    "\n",
    "for label, x, y in zip(labels, petal_scaled[:, 0], petal_scaled[:, 1]):\n",
    "    plt.annotate(\n",
    "        label,\n",
    "        xy=(x, y), xytext=(-3, 3),\n",
    "        textcoords='offset points', ha='right', va='bottom')\n",
    "plt.show()\n",
    "bestselouette2=[]\n",
    "bestselouette3=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbb=np.array(my_data)\n",
    "clustering = AgglomerativeClustering().fit(sepal_scaled)\n",
    "clustering\n",
    "AgglomerativeClustering()\n",
    "clustering.labels_\n",
    "#here we are drawing the data to know by eyes how many clusters we can make\n",
    "labels = range(1, 11)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.subplots_adjust(bottom=0.1)\n",
    "plt.scatter(sepal_scaled[:,0],sepal_scaled[:,1], label='True Position')\n",
    "\n",
    "for label, x, y in zip(labels, sepal_scaled[:, 0], sepal_scaled[:, 1]):\n",
    "    plt.annotate(\n",
    "        label,\n",
    "        xy=(x, y), xytext=(-3, 3),\n",
    "        textcoords='offset points', ha='right', va='bottom')\n",
    "plt.show()\n",
    "bestselouette2=[]\n",
    "bestselouette3=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = KMeans() \n",
    "    visualizer = KElbowVisualizer(model, k=(2,15), metric='distortion', timings=False)\n",
    "    visualizer.fit(sepal_scaled)    \n",
    "    visualizer.poof()\n",
    "    n=visualizer.elbow_value_.T\n",
    "    visualizer2 = KElbowVisualizer(model, k=(2,15), metric='silhouette', timings=False)\n",
    "    visualizer2.fit(sepal_scaled)\n",
    "    elbow_score=visualizer2.elbow_score_.T\n",
    "    km =KMeans(n_clusters =n).fit(sepal_scaled)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(sepal_scaled[:,0], sepal_scaled[:,1], c=km.labels_, cmap='viridis')\n",
    "    strm=\"the best sil score of Manhattan single is at cluster:\"\n",
    "    kk=\" and of value equal to:\"\n",
    "    print(strm+ \" \"+ str(elbow_score)+\" \"+kk+\" \"+str(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = KMeans() \n",
    "    visualizer = KElbowVisualizer(model, k=(2,15), metric='distortion', timings=False)\n",
    "    visualizer.fit(petal_scaled)    \n",
    "    visualizer.poof()\n",
    "    n=visualizer.elbow_value_.T\n",
    "    visualizer2 = KElbowVisualizer(model, k=(2,15), metric='silhouette', timings=False)\n",
    "    visualizer2.fit(petal_scaled)\n",
    "    elbow_score=visualizer2.elbow_score_.T\n",
    "    km =KMeans(n_clusters =n).fit(petal_scaled)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(petal_scaled[:,0], petal_scaled[:,1], c=km.labels_, cmap='viridis')\n",
    "    strm=\"the best sil score of Manhattan single is at cluster:\"\n",
    "    kk=\" and of value equal to:\"\n",
    "    print(strm+ \" \"+ str(elbow_score)+\" \"+kk+\" \"+str(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepal=sepal_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,10):\n",
    "            GM = GaussianMixture(n_components=i,covariance_type='full').fit(sepal)\n",
    "            plt.scatter(sepal[:, 0], sepal[:, 1], c=GM.predict(sepal), cmap='rainbow');\n",
    "            X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "            XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "            Z = GM.score_samples(XX)\n",
    "            Z = Z.reshape((50,50))\n",
    "            plt.contour(X, Y, Z,levels=50) \n",
    "            plt.title('Guassian full sepal')\n",
    "            plt.scatter(sepal[:, 0], sepal[:, 1], c=GM.predict(sepal), cmap='rainbow');\n",
    "            plt.show()\n",
    "for i in range(2,10):          \n",
    "            GM = GaussianMixture(n_components=i,covariance_type='spherical').fit(sepal)\n",
    "            plt.scatter(sepal[:, 0], sepal[:, 1], c=GM.predict(sepal), cmap='rainbow');\n",
    "            X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "            XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "            Z = GM.score_samples(XX)\n",
    "            Z = Z.reshape((50,50))\n",
    "            plt.contour(X, Y, Z,levels=50)\n",
    "            plt.title('Guassian spherical sepal')\n",
    "            plt.scatter(sepal[:, 0], sepal[:, 1], c=GM.predict(sepal), cmap='rainbow');\n",
    "            plt.show()\n",
    "for i in range(2,10):\n",
    "            GM = GaussianMixture(n_components=i,covariance_type='tied').fit(sepal)\n",
    "            plt.scatter(sepal[:, 0], sepal[:, 1], c=GM.predict(sepal), cmap='rainbow');\n",
    "            X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "            XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "            Z = GM.score_samples(XX)\n",
    "            Z = Z.reshape((50,50))\n",
    "            plt.contour(X, Y, Z,levels=50)\n",
    "            plt.title('Guassian tied sepal')\n",
    "            plt.scatter(sepal[:, 0], sepal[:, 1], c=GM.predict(sepal), cmap='rainbow');\n",
    "            plt.show()\n",
    "for i in range(2,10):\n",
    "            GM = GaussianMixture(n_components=i,covariance_type='diag').fit(sepal)\n",
    "            plt.scatter(sepal[:, 0], sepal[:, 1], c=GM.predict(sepal), cmap='rainbow');\n",
    "            X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "            XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "            Z = GM.score_samples(XX)\n",
    "            Z = Z.reshape((50,50))\n",
    "            plt.contour(X, Y, Z,levels=50) \n",
    "            plt.title('Guassian diag sepal')\n",
    "            plt.scatter(sepal[:, 0], sepal[:, 1], c=GM.predict(sepal), cmap='rainbow');\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petal=petal_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for i in range(2,10):            \n",
    "            GM = GaussianMixture(n_components=i,covariance_type='full').fit(petal)\n",
    "            plt.scatter(petal[:, 0], petal[:, 1], c=GM.predict(petal), cmap='rainbow');\n",
    "            X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "            XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "            Z = GM.score_samples(XX)\n",
    "            Z = Z.reshape((50,50))\n",
    "            plt.contour(X, Y, Z,levels=50) \n",
    "            plt.title('Guassian full petal')\n",
    "            plt.scatter(petal[:, 0], petal[:, 1], c=GM.predict(petal), cmap='rainbow');\n",
    "            plt.show()\n",
    "    for i in range(2,10):\n",
    "            GM = GaussianMixture(n_components=i,covariance_type='spherical').fit(petal)\n",
    "            plt.scatter(petal[:, 0], petal[:, 1], c=GM.predict(petal), cmap='rainbow');\n",
    "            X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "            XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "            Z = GM.score_samples(XX)\n",
    "            Z = Z.reshape((50,50))\n",
    "            plt.contour(X, Y, Z,levels=50) \n",
    "            plt.title('Guassian spherical petal')\n",
    "            plt.scatter(petal[:, 0], petal[:, 1], c=GM.predict(petal), cmap='rainbow');\n",
    "            plt.show()\n",
    "    for i in range(2,10):\n",
    "            GM = GaussianMixture(n_components=i,covariance_type='tied').fit(petal)\n",
    "            plt.scatter(petal[:, 0], petal[:, 1], c=GM.predict(petal), cmap='rainbow');\n",
    "            X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "            XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "            Z = GM.score_samples(XX)\n",
    "            Z = Z.reshape((50,50))\n",
    "            plt.contour(X, Y, Z,levels=50) \n",
    "            plt.title('Guassian tied petal')\n",
    "            plt.scatter(petal[:, 0], petal[:, 1], c=GM.predict(petal), cmap='rainbow');\n",
    "            plt.show()\n",
    "    for i in range(2,10):\n",
    "            GM = GaussianMixture(n_components=i,covariance_type='diag').fit(petal)\n",
    "            plt.scatter(petal[:, 0], petal[:, 1], c=GM.predict(petal), cmap='rainbow');\n",
    "            X, Y = np.meshgrid(np.linspace(-6,15), np.linspace(-6,15))\n",
    "            XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "            Z = GM.score_samples(XX)\n",
    "            Z = Z.reshape((50,50))\n",
    "            plt.contour(X, Y, Z,levels=50) \n",
    "            plt.title('Guassian diag petal')\n",
    "            plt.scatter(petal[:, 0], petal[:, 1], c=GM.predict(petal), cmap='rainbow');\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestselouette2=[]\n",
    "bestselouette3=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbb=sepal_scaled\n",
    "bbbb=petal_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manhattan single Dendogram \n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of single Manhattan distance\")\n",
    "dend = shc.dendrogram(shc.linkage(bbb, method='single',metric='cityblock'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "#Manhattan single before clustering\n",
    "rangee=[]\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster2 = AgglomerativeClustering(n_clusters=2, affinity='manhattan', linkage='single')\n",
    "cluster2.fit_predict(bbb)\n",
    "print(cluster2.labels_)\n",
    "plt.scatter(bbb[:,0],bbb[:,1], c=cluster2.labels_, cmap='viridis')\n",
    "rangee.append(np.array(cluster2))#Manhattan single after clustering \n",
    "bestselouette1=[]\n",
    "score=[]\n",
    "distanceofbestsill=[]\n",
    "strm=[]\n",
    "bestsil=[]\n",
    "strmm=[]\n",
    "kk=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "for i in np.arange(mi,ma,r):\n",
    "    cluster = AgglomerativeClustering(n_clusters=None, affinity='manhattan', linkage='single',distance_threshold=i)\n",
    "    cluster.fit_predict(bbb)\n",
    "    acluster.append(len(np.unique(cluster.labels_)))\n",
    "    score.append(silhouette_score(bbb, cluster.labels_, metric='manhattan'))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(bbb[:,0], bbb[:,1], c=cluster.labels_, cmap='viridis')\n",
    "    hi.append(i)\n",
    "bestsil.append(max(score))\n",
    "print(\"hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\")\n",
    "\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(\"jjjjjjjjjjjjjjjjijjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj\")\n",
    "print(acluster[iii])\n",
    "strm=\"the best sil score of Manhattan single is at cluster:\"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manhattan single Dendogram \n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of single Manhattan distance\")\n",
    "dend = shc.dendrogram(shc.linkage(bbbb, method='single',metric='cityblock'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "#Manhattan single before clustering\n",
    "rangee=[]\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster2 = AgglomerativeClustering(n_clusters=2, affinity='manhattan', linkage='single')\n",
    "cluster2.fit_predict(bbbb)\n",
    "print(cluster2.labels_)\n",
    "plt.scatter(bbbb[:,0],bbbb[:,1], c=cluster2.labels_, cmap='viridis')\n",
    "rangee.append(np.array(cluster2))#Manhattan single after clustering \n",
    "bestselouette1=[]\n",
    "score=[]\n",
    "distanceofbestsill=[]\n",
    "strm=[]\n",
    "bestsil=[]\n",
    "strmm=[]\n",
    "kk=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "for i in np.arange(mi,ma,r):\n",
    "    cluster = AgglomerativeClustering(n_clusters=None, affinity='manhattan', linkage='single',distance_threshold=i)\n",
    "    cluster.fit_predict(bbbb)\n",
    "    acluster.append(len(np.unique(cluster.labels_)))\n",
    "    score.append(silhouette_score(bbbb, cluster.labels_, metric='manhattan'))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(bbbb[:,0], bbbb[:,1], c=cluster.labels_, cmap='viridis')\n",
    "    hi.append(i)\n",
    "bestsil.append(max(score))\n",
    "print(\"hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\")\n",
    "\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(\"jjjjjjjjjjjjjjjjijjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj\")\n",
    "print(acluster[iii])\n",
    "strm=\"the best sil score of Manhattan single is at cluster:\"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manhattan average Dendogram \n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of average Manhattan distance\")\n",
    "dend = shc.dendrogram(shc.linkage(bbb, method='average',metric='cityblock'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "#Manhattan single before clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster2 = AgglomerativeClustering(n_clusters=2, affinity='manhattan', linkage='average')\n",
    "cluster2.fit_predict(bbb)\n",
    "print(cluster2.labels_)\n",
    "plt.scatter(bbb[:,0],bbb[:,1], c=cluster2.labels_, cmap='viridis')\n",
    "#Manhattan average after clustering \n",
    "bestselouette1=[]\n",
    "score=[]\n",
    "distanceofbestsill=[]\n",
    "strm=[]\n",
    "bestsil=[]\n",
    "strmm=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "for i in np.arange(mi,ma,r):\n",
    "    cluster = AgglomerativeClustering(n_clusters=None, affinity='manhattan', linkage='average',distance_threshold=i)\n",
    "    cluster.fit_predict(bbb)\n",
    "    score.append(silhouette_score(bbb, cluster.labels_, metric='manhattan'))\n",
    "    acluster.append(len(np.unique(cluster.labels_)))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(bbb[:,0], bbb[:,1], c=cluster.labels_, cmap='viridis')\n",
    "    hi.append(i)\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "strm=\"the best sil score of Manhattan average is at cluster:\"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manhattan average Dendogram \n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of average Manhattan distance\")\n",
    "dend = shc.dendrogram(shc.linkage(bbbb, method='average',metric='cityblock'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "#Manhattan single before clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster2 = AgglomerativeClustering(n_clusters=2, affinity='manhattan', linkage='average')\n",
    "cluster2.fit_predict(bbbb)\n",
    "print(cluster2.labels_)\n",
    "plt.scatter(bbbb[:,0],bbbb[:,1], c=cluster2.labels_, cmap='viridis')\n",
    "#Manhattan average after clustering \n",
    "bestselouette1=[]\n",
    "score=[]\n",
    "distanceofbestsill=[]\n",
    "strm=[]\n",
    "bestsil=[]\n",
    "strmm=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "for i in np.arange(mi,ma,r):\n",
    "    cluster = AgglomerativeClustering(n_clusters=None, affinity='manhattan', linkage='average',distance_threshold=i)\n",
    "    cluster.fit_predict(bbbb)\n",
    "    score.append(silhouette_score(bbbb, cluster.labels_, metric='manhattan'))\n",
    "    acluster.append(len(np.unique(cluster.labels_)))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(bbbb[:,0], bbbb[:,1], c=cluster.labels_, cmap='viridis')\n",
    "    hi.append(i)\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "strm=\"the best sil score of Manhattan average is at cluster:\"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean single \n",
    "#before clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of single Euclidean distance\")\n",
    "dend = shc.dendrogram(shc.linkage(bbb, method='single'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster11 = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='single')\n",
    "cluster11.fit_predict(bbb)\n",
    "print(cluster11.labels_)\n",
    "plt.scatter(bbb[:,0],bbb[:,1], c=cluster11.labels_, cmap='viridis')\n",
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "# Euclidean average after clustering\n",
    "indexat=[1.0,1.25,1.5,1.75,2.0,2.25,2.5,2.75]\n",
    "#for i in indexat:\n",
    "    #print(i)\n",
    "for i in np.arange(mi,ma,r):\n",
    "#for i in indexat :\n",
    "    \n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='euclidean', linkage='single',distance_threshold=i)\n",
    "    clusterEA.fit_predict(bbb)\n",
    "    score.append(silhouette_score(bbb, clusterEA.labels_, metric='euclidean'))\n",
    "    hi.append(i)\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(bbb[:,0], bbb[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "strm=\"the best sil score of Eucilidean single is at cluster of  \"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "\n",
    "kk=\" at distance threshold:\"\n",
    "#print(str(a[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean single \n",
    "#before clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of single Euclidean distance\")\n",
    "dend = shc.dendrogram(shc.linkage(bbbb, method='single'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster11 = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='single')\n",
    "cluster11.fit_predict(bbbb)\n",
    "print(cluster11.labels_)\n",
    "plt.scatter(bbbb[:,0],bbbb[:,1], c=cluster11.labels_, cmap='viridis')\n",
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "# Euclidean average after clustering\n",
    "indexat=[1.0,1.25,1.5,1.75,2.0,2.25,2.5,2.75]\n",
    "#for i in indexat:\n",
    "    #print(i)\n",
    "for i in np.arange(mi,ma,r):\n",
    "#for i in indexat :\n",
    "    \n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='euclidean', linkage='single',distance_threshold=i)\n",
    "    clusterEA.fit_predict(bbbb)\n",
    "    score.append(silhouette_score(bbbb, clusterEA.labels_, metric='euclidean'))\n",
    "    hi.append(i)\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(bbbb[:,0], bbbb[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "strm=\"the best sil score of Eucilidean single is at cluster of  \"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "\n",
    "kk=\" at distance threshold:\"\n",
    "#print(str(a[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean average before clustering\n",
    "# Euclidean average before clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of single Euclidean distance\")\n",
    "dend = shc.dendrogram(shc.linkage(irisdata, method='single'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster1 = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='average')\n",
    "cluster1.fit_predict(bbb)\n",
    "print(cluster1.labels_)\n",
    "plt.scatter(bbb[:,0],bbb[:,1], c=cluster1.labels_, cmap='viridis')\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of Average Euclidean distance\")\n",
    "dend = shc.dendrogram(shc.linkage(bbb, method='average'))\n",
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "# Euclidean average after clustering\n",
    "\n",
    "for i in np.arange(20000,160000,20000):\n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='euclidean', linkage='average',distance_threshold=i)\n",
    "    clusterEA.fit_predict(bbb)\n",
    "    score.append(silhouette_score(bbb, clusterEA.labels_, metric='euclidean'))\n",
    "    hi.append(i)\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(bbb[:,0], bbb[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)+1\n",
    "print(iii)\n",
    "strm=\"the best sil score of Eucilidean average is at cluster of  \"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean average before clustering\n",
    "# Euclidean average before clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of single Euclidean distance\")\n",
    "dend = shc.dendrogram(shc.linkage(irisdata, method='single'))\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster1 = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='average')\n",
    "cluster1.fit_predict(bbbb)\n",
    "print(cluster1.labels_)\n",
    "plt.scatter(bbbb[:,0],bbbb[:,1], c=cluster1.labels_, cmap='viridis')\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of Average Euclidean distance\")\n",
    "dend = shc.dendrogram(shc.linkage(bbbb, method='average'))\n",
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "# Euclidean average after clustering\n",
    "\n",
    "for i in np.arange(mi,ma,r):\n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='euclidean', linkage='average',distance_threshold=i)\n",
    "    clusterEA.fit_predict(bbbb)\n",
    "    score.append(silhouette_score(bbbb, clusterEA.labels_, metric='euclidean'))\n",
    "    hi.append(i)\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(bbbb[:,0], bbbb[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)+1\n",
    "print(iii)\n",
    "strm=\"the best sil score of Eucilidean average is at cluster of  \"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine single before clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of single cosine distance\")\n",
    "dend = shc.dendrogram(shc.linkage(bbb, method='single',metric='cosine'))\n",
    "\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "clusterEA12 = AgglomerativeClustering(n_clusters=2, affinity='cosine', linkage='single')\n",
    "clusterEA12.fit_predict(bbb)\n",
    "print(clusterEA12.labels_)\n",
    "plt.scatter(bbb[:,0],bbb[:,1], c=clusterEA12.labels_, cmap='viridis')\n",
    "# cosine single after clustering\n",
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "# Euclidean average after clustering\n",
    "# heya men 0-1.6 bs msh zabta m3aya \n",
    "iteraty=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "for i in np.arange(mi,ma,r):\n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='cosine', linkage='single',distance_threshold=i)\n",
    "    clusterEA.fit_predict(bbb)\n",
    "    score.append(silhouette_score(bbb, clusterEA.labels_, metric='cosine'))\n",
    "    hi.append(i)\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(bbb[:,0], bbb[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "print(\"kkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk\")\n",
    "print(hi[iii])\n",
    "strm=\"the best sil score of cosine single is at cluster of  \"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster\n",
    "                                   [iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine single before clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of single cosine distance\")\n",
    "dend = shc.dendrogram(shc.linkage(bbb, method='single',metric='cosine'))\n",
    "\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "clusterEA12 = AgglomerativeClustering(n_clusters=2, affinity='cosine', linkage='single')\n",
    "clusterEA12.fit_predict(bbbb)\n",
    "print(clusterEA12.labels_)\n",
    "plt.scatter(bbbb[:,0],bbbb[:,1], c=clusterEA12.labels_, cmap='viridis')\n",
    "# cosine single after clustering\n",
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "# Euclidean average after clustering\n",
    "# heya men 0-1.6 bs msh zabta m3aya \n",
    "iteraty=[]\n",
    "hi=[]\n",
    "acluster=[]\n",
    "for i in np.arange(mi,ma,r):\n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='cosine', linkage='single',distance_threshold=i)\n",
    "    clusterEA.fit_predict(bbbb)\n",
    "    score.append(silhouette_score(bbbb, clusterEA.labels_, metric='cosine'))\n",
    "    hi.append(i)\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(bbbb[:,0], bbbb[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "print(\"kkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk\")\n",
    "print(hi[iii])\n",
    "strm=\"the best sil score of cosine single is at cluster of  \"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster\n",
    "                                   [iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine average before clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of Cosine Average distance\")\n",
    "dend = shc.dendrogram(shc.linkage(bbb, method='average',metric='cosine'))# Euclidean average before clustering\n",
    "\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "clusterEA1 = AgglomerativeClustering(n_clusters=2, affinity='cosine', linkage='average')\n",
    "clusterEA1.fit_predict(bbb)\n",
    "print(clusterEA1.labels_)\n",
    "plt.scatter(bbb[:,0],bbb[:,1], c=clusterEA1.labels_, cmap='viridis')\n",
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "hi=[]\n",
    "# Euclidean average after clustering\n",
    "# heya men 0-1.6 bs msh zabta m3aya \n",
    "iteraty=[]\n",
    "acluster=[]\n",
    "for i in np.arange(mi,ma,r):\n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='cosine', linkage='average',distance_threshold=i)\n",
    "    clusterEA.fit_predict(bbb)\n",
    "    score.append(silhouette_score(bbb, clusterEA.labels_, metric='cosine'))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    hi.append(i)\n",
    "    plt.scatter(bbb[:,0], bbb[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "print(\"kkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk\")\n",
    "print(hi[iii])\n",
    "strm=\"the best sil score of cosine average is at cluster of  \"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine average before clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms of Cosine Average distance\")\n",
    "dend = shc.dendrogram(shc.linkage(bbbb, method='average',metric='cosine'))# Euclidean average before clustering\n",
    "\n",
    "mi=np.min(dend['dcoord'])\n",
    "ma=np.max(dend['dcoord'])\n",
    "r=((ma-mi))/10\n",
    "if mi==0.0:\n",
    "    mi=mi+r\n",
    "print(mi,ma,r)\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "clusterEA1 = AgglomerativeClustering(n_clusters=2, affinity='cosine', linkage='average')\n",
    "clusterEA1.fit_predict(bbbb)\n",
    "print(clusterEA1.labels_)\n",
    "plt.scatter(bbbb[:,0],bbbb[:,1], c=clusterEA1.labels_, cmap='viridis')\n",
    "bestselouette1=[]\n",
    "distanceofbestsill=[]\n",
    "bestsil=[]\n",
    "strm=[]\n",
    "score=[]\n",
    "hi=[]\n",
    "# Euclidean average after clustering\n",
    "# heya men 0-1.6 bs msh zabta m3aya \n",
    "iteraty=[]\n",
    "acluster=[]\n",
    "for i in np.arange(mi,ma,r):\n",
    "    clusterEA = AgglomerativeClustering(n_clusters=None, affinity='cosine', linkage='average',distance_threshold=i)\n",
    "    clusterEA.fit_predict(bbbb)\n",
    "    score.append(silhouette_score(bbbb, clusterEA.labels_, metric='cosine'))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    acluster.append(len(np.unique(clusterEA.labels_)))\n",
    "    hi.append(i)\n",
    "    plt.scatter(bbbb[:,0], bbbb[:,1], c=clusterEA.labels_, cmap='viridis')\n",
    "bestsil.append(max(score))\n",
    "print(bestsil)\n",
    "iii=score.index(bestsil)\n",
    "print(iii)\n",
    "print(\"kkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk\")\n",
    "print(hi[iii])\n",
    "strm=\"the best sil score of cosine average is at cluster of  \"\n",
    "kk=\" at distance threshold:\"\n",
    "print(str(acluster[iii]))\n",
    "print(str(bestsil))\n",
    "bestselouette1.append(strm+' '+str(acluster[iii])+''+kk)\n",
    "bestselouette2=bestselouette1+bestsil \n",
    "bestselouette3.append(bestselouette2)\n",
    "print(bestselouette3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in bestselouette3:\n",
    "    print(each)\n",
    "    m=str(each[0])\n",
    "    n=str(each[1])\n",
    "res = [] \n",
    "m = \"\"\n",
    "ar=[]\n",
    "final=[]\n",
    "[res.append(x) for x in bestselouette3 if x not in res]\n",
    "for each in res:\n",
    "    m=str(each[0])\n",
    "    n=str(each[1])\n",
    "    ar.append(n)\n",
    "    final.append(m)\n",
    "    final.append(n)\n",
    "    s=(max(ar))\n",
    "\n",
    "#print(final)   \n",
    "ss=final.index(s)\n",
    "sss=final[ss-1]\n",
    "print (\"The best technique and the best score are                                       :                                 \")\n",
    "print(sss+\"  and is equal to \"+s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    xx=np.arange(0.1,3,0.1)\n",
    "    yy=range(5,25)\n",
    "    sil=np.empty((len(ii),len(jj)),float)\n",
    "    a=0\n",
    "    b=0\n",
    "    for i in xx :\n",
    "        for j in yy :\n",
    "            DBScan = DBSCAN(eps=i, min_samples=j).fit(bbb)\n",
    "            plt.scatter(bbb[:,0], bbb[:,1], c=DBScan.labels_, cmap='rainbow')\n",
    "            plt.title(\"eps=\"+str(i)[0:3]+\"   min_samples\"+str(j))\n",
    "            plt.show()\n",
    "            n=len(set(DBScan.labels_))\n",
    "            if(n>1):\n",
    "                sil[a][b]=silhouette_score(bbb,DBScan.labels_)         \n",
    "            else :\n",
    "                sil[a][b]=-1\n",
    "            b+=1\n",
    "        a+=1\n",
    "        b=0\n",
    "    plt.colorbar(plt.imshow(sil,cmap='viridis'))\n",
    "    plt.clf()\n",
    "    maxindex=np.unravel_index(sil.argmax(), sil.shape)\n",
    "    besteps=xx[maxindex[0]]\n",
    "    bestmin_samples=yy[maxindex[1]]\n",
    "    DBScan = DBSCAN(eps=besteps, min_samples=bestmin_samples).fit(bbb)\n",
    "    plt.scatter(bbb[:,0], bbb[:,1], c=DBScan.labels_, cmap='rainbow')\n",
    "    plt.title(\"eps=\"+str(best_eps)+\"   min_samples\"+str(bestmin_samples))\n",
    "    plt.show()\n",
    "    max_score=sil[maxindex[0]][maxindex[1]]\n",
    "    print(\"the best value of eps is: \" +str(best_eps))\n",
    "    print(\"the best value of min_samples is: \" +str(best_min_samples))\n",
    "    print(\"the max silhouette score is :  \" + str(max_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments and Review :\n",
    "When dealing with :\n",
    "Multi_blob_Data\n",
    "K means was the best techique for clustering since it had the best silhouette score of 0.4751544541991239  and of value of k equal to: 6\n",
    "while the best hierechial technique was cosine average since it gave us a silhouette score equal to 0.9078745871299884 and at a k of 2 \n",
    "while the DB scan had a silhouette score of 0.4685207355522043 at k = 5 \n",
    "so, K means is the best in the first data.\n",
    "Iris data :\n",
    "K means gives us silhoutte score of 0.6810461692117462  and of atequal to: 4\n",
    "while the best hierechial technique wascosine average is at cluster of   2  and silhouette score  equal to 0.9581279477970689\n",
    "while the DB scan had a silhouette score 0.6867350732769777 at k = 5 \n",
    "DB scan is the best for the iris data\n",
    "Customer data :\n",
    "the best sil score of k means is of value 0.5834469001696239  and of cluster equal to: 5\n",
    "while the best hierechial technique was cosine average since it gave us a silhouette score equal to 0.9078745871299884 and at a k of 2 \n",
    "while the DB scan had a silhouette score of the best value of eps is: -1.0 at k =5\n",
    "K means is the best in customer data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    xx=np.arange(0.1,3,0.1)\n",
    "    yy=range(5,25)\n",
    "    sil=np.empty((len(ii),len(jj)),float)\n",
    "    a=0\n",
    "    b=0\n",
    "    for i in xx :\n",
    "        for j in yy :\n",
    "            DBScan = DBSCAN(eps=i, min_samples=j).fit(bbbb)\n",
    "            plt.scatter(bbbb[:,0], bbbb[:,1], c=DBScan.labels_, cmap='rainbow')\n",
    "            plt.title(\"eps=\"+str(i)[0:3]+\"   min_samples\"+str(j))\n",
    "            plt.show()\n",
    "            n=len(set(DBScan.labels_))\n",
    "            if(n>1):\n",
    "                sil[a][b]=silhouette_score(bbbb,DBScan.labels_)         \n",
    "            else :\n",
    "                sil[a][b]=-1\n",
    "            b+=1\n",
    "        a+=1\n",
    "        b=0\n",
    "    plt.colorbar(plt.imshow(sil,cmap='viridis'))\n",
    "    plt.clf()\n",
    "    maxindex=np.unravel_index(sil.argmax(), sil.shape)\n",
    "    besteps=xx[maxindex[0]]\n",
    "    bestmin_samples=yy[maxindex[1]]\n",
    "    DBScan = DBSCAN(eps=besteps, min_samples=bestmin_samples).fit(bbbb)\n",
    "    plt.scatter(bbbb[:,0], bbbb[:,1], c=DBScan.labels_, cmap='rainbow')\n",
    "    plt.title(\"eps=\"+str(best_eps)+\"   min_samples\"+str(bestmin_samples))\n",
    "    plt.show()\n",
    "    max_score=sil[maxindex[0]][maxindex[1]]\n",
    "    print(\"the best value of eps is: \" +str(best_eps))\n",
    "    print(\"the best value of min_samples is: \" +str(best_min_samples))\n",
    "    print(\"the max silhouette score is :  \" + str(max_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Clustering Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
